{
  "0": {
    "title": "Auditlog",
    "content": "Introduction . This document describes the evaluation of the work package formerly known as “CRUD Monitoring”. This work package is part of the Open Integration Hub. . After a first draft of a “CRUD Monitoring” service, we changed the scope of the service and decided to develop an “Audit Log”-Service. After some evaluations we now try to broaden the scope to a more general log monitoring from which we can do different kind of audits and other kind of monitoring, e.g. performance and error logging. . Log monitors are a type of software that monitor log files. Servers, application, network and security devices generate log files. Errors, problems, and more information is constantly logged and saved for analysis. The log monitors scan the log files and search for known text patterns and rules that indicate important events. . One crucial task is the audit logging. An audit log is a chronological record of system activities to enable the reconstruction and examination of the sequence of events and / or changes in an event. In the case of user audit log it helps to know what actions a user has recently performed. . Description . Purpose of log monitoring . In order to detect problems and see the status of the system automatically, system administrators set up monitors on the generated logs. Once an event is detected, the monitoring system helps to identify events that occurred or might occur. . For an audit log the log monitoring can be used to prevent suspicious activity when it starts (if actively monitored), or to play back account activity during an incident review. Because of the nature of the OIH it’s crucial to do this, because without appropriate audit logging, any security critical activities can go unnoticed. And evidence of whether or not a possible attack led to a breach can be inconclusive. . Requirements for log monitoring . Within the Open Integration Hub we have to consider how we are fulfilling the following tasks for logging and monitoring: . log the relevant activity into a system that is immutable | time stamp this activities | let them be accessible by admin accounts | let them be exportable | . For an audit log data should never change. By default an audit log should generally be kept for 1-3 years. The timeframe should be documented and configurable (generally shorter) for customers who have data retention requirements. . Events to audit log . Audit logging functionality requires a clear understanding of which events should be recorded in the audit log. The ISO-27002 specifications provide some clarity about what enterprise customers will likely need to have logged. . Generally, the specific content of a target is not audit logged, rather the state or context is logged. . Examples of events that should be audit logged are as follows: . specific user activities, | exceptions, | information about security events (successful and rejected events), | use of privileges and the use of advanced privileges | failed login attempts | administrative configuration changes | . Actions can generally be categorized into their CRUD type (i.e. Create, Read, Update, or Delete). . In case of a logged event we need to provide enough information about the event to provide the necessary context of who, what, when and where etc. . Technology Used . The Open Integration Hub is running inside a Kubernetes cluster with all the Docker containers for the microservices and the integration flows. The easiest logging method for containerized applications is to write to the standard output and standard error streams. In Kubernetes one can implement cluster-level logging by installing a logging agent on each node. Most of the K8s hosting services provide this by default. . Elasticsearch, Logstash and Kibana, known as ELK stack or Elastic stack are very common tools for logs aggregation and analysis. . For the first draft of a CRUD Monitoring Service, we evaluated Logstash very deeply. Logstash is a tool to collect, parse and store logs and events. It reads the logs via so called inputs, parses, aggregates and filters with the help of filters and stores by outputs. Logstash provides an input stream to Elasticsearch for storage and search, and Kibana accesses the data for visualizations such as dashboards. . Elasticsearch is a search engine based on the Lucene library. It provides a distributed, multitenant-capable full-text search engine with an HTTP web interface and schema-free JSON documents. . Kibana is an open source data visualization plugin for Elasticsearch. It provides visualization capabilities on top of the content indexed on an Elasticsearch cluster. . To feed the logs to the ELK stack we need some more tools, like “Beats”. With Beats we can gather log data from different sources and then centralize the data in Elasticsearch. . Monitoring and Logging Concept . At first, Logstash extracts the monitored data with event processing. This process consists of three stages: Input, then filtering and at last the output. Logstash is controlled through proprietary config files, which are mounted in a dedicated volume. . In the input stage Logstash gets the data from the source. Upon receiving events, Logstash performs an action based on the conditional filter, which means it will be transformed from unstructured to structured data. So we will have a normalised schema which is enriched with relevant metadata. . Logstash then delivers the data to Elasticsearch. Elasticsearch will typically store a document once for each repository in which it resides. Each document is a simple set of correlating keys and values: the keys are strings, and the values are one of numerous data types—strings, numbers, dates, or lists. . With Kibana we can search, view, and interact with data stored in Elasticsearch indices. Its simple, browser-based interface enables you to quickly create and share dynamic dashboards that display changes to Elasticsearch queries in real time. . On the Google Compute Engine (GCE) platform, the default logging support targets Stackdriver Logging. As of now you cannot automatically deploy Elasticsearch and Kibana in the Kubernetes cluster hosted on Google Kubernetes Engine. You have to deploy them manually. . API Specs . Draft 0.0.2 .",
    "url": "http://localhost:4000/docs/Services/AuditLog.html",
    "relUrl": "/docs/Services/AuditLog.html"
  },
  "1": {
    "title": "Component Orchestrator",
    "content": "Introduction . The service component orchestrator is responsible for a fair resource distribution. . Description . The document shortly describes the service and its functionality. . Service Implementation . Framework Part: component orchestrator lib . Reference Implementation: component orchestrator service . Conceptional Elaborations . Component Orchestrator . In a multi-tenant environment it must be guaranteed that a user or tenant (intentionally or unintentionally) may not get an unfair usage of shared resources such as CPU, Memory, Network, etc. It must be guaranteed that every integration flow gets a chance to be executed, close to the intervals defined by its Cron expression. . The Component Orchestrator is a micro-service defining the fairness policy and controlling that each user/flow/tenant is complying with that policy. The Component Orchestrator is responsible for: . Protection from over-scheduling: if an execution of a flow takes longer than its scheduling interval, the following executions must be skipped. | Making sure that a flow or its steps are not deployed multiple times | If scaling is configured for a flow, the specified number of instances must be deployed | Detection of policy violations and punishment of “bad citizens” | .",
    "url": "http://localhost:4000/docs/Services/ComponentOrchestrator.html",
    "relUrl": "/docs/Services/ComponentOrchestrator.html"
  },
  "2": {
    "title": "Component Repository",
    "content": "Introduction . The component repository is needed to store integration components such as adapters &amp; transformer. . Description . The documents shorty describes integration components and how they are stored, retreived and managed. . Service Implementation . Framework Part: component repository lib . Reference Implementation: component orchestrator service . Reasoning . Docker Registry: Stateless, highly scalable storage for Docker images | . Conceptional Elaborations . The integration components are lightweight and stand-alone Docker images that include everything needed to run the component, including the component’s code, a runtime, libraries and dependencies. Each component is based on an Open Integration Hub parent image which provides the component runtime. For example, for Java component the parent images provides the JDK and for Node.js component the parent image provides NPM and Node.js. . The component images are stored in a Docker Registry. A Docker Registry is a stateless, highly scalable storage for Docker images. Any open source integration component can be store and distributed in/from Docker Cloud so that they would be available to any OIH installations (cloud or on-prem) out of the box. For private components private Docker Registry can be maintained locally so that no components are exposed to the cloud. Each on prem installation could decide whether to use private repos on Docker Cloud or installing a private Docker Registry on prem for their private components. .",
    "url": "http://localhost:4000/docs/Services/ComponentRepository.html",
    "relUrl": "/docs/Services/ComponentRepository.html"
  },
  "3": {
    "title": "Flow Repository",
    "content": "Flow Repository . Introduction . This document describes the evaluation of the Microservice “Flow Repository”. This microservice is part of the integration services of the Open Integration Hub. . Description . Purpose of the Microservice Flow Repository . If we talk about “content” here, we mean “flows”. All connected solutions and to the Open Integration Hub and the work they are doing there are represented by an “integration flows”. A data modification in one of the affected systems should propagate to all connected solutions / systems as defined in the corresponding integration flows. . The integration flows are defined by a single user of the Open Integration Hub or a member of an organization which uses the Open Integration Hub. . These flows have to be stored, retrieved, updated and deleted. The Flow Repository will provide these functionabilities. . Service Implementation . Framework Part: Tbd . Reference Implementation: flow repository service . Requirements for the Flow Repository . We will need a component within the Open Integration Hub which fulfill the following user stories. . | User story: | As a user I want to store an integration flow for a specific integration task | | :— | :— | . | User story: | As a user I want to retrieve the integration flows of a specific user | | :— | :— | . | User story: | As a user I want to update the integration flows of a specific user | | :— | :— | . | User story: | As a user I want to delete the integration flows of a specific user | | :— | :— | . | User story: | As a user I want to retrieve a specific integration flows by its id | | :— | :— | . This will lead to the following use cases: . Label USE CASE - Store Integration Flow . Actor: | User | . Summary: | Describes adding a new integration flow | . Trigger: | A user wants to store a new integration flow | . Preconditions: | Credentials for the user are given | . Main Success Scenario: | Added integration flow | . Failure Scenario: | Adding new flow was not successful | . Basic Workflow: | 1. Define user 2. Define flow 3. Store flow | . Alternative Workflow: | 1a. User is unknown 2a. Incorrect flow defined 3a. Throw error | . Label USE CASE - Retrieve Integration Flow . Actor: | User | . Summary: | Describes retrieving a given integration flow | . Trigger: | A user wants to retrieve an integration flow | . Preconditions: | Credentials for the user are given | . Main Success Scenario: | Flow retrieved | . Failure Scenario: | Retrieving the flow was not successful | . Basic Workflow: | 1. Define user 2. Define flow 3. Retrieve flow | . Alternative Workflow: | 1a. User is unknown 2a. Incorrect flow defined 3a. Throw error | . Label USE CASE - Update Integration Flow . Actor: | User | . Summary: | Describes updating a given integration flow | . Trigger: | A user wants to update an integration flow | . Preconditions: | Credentials for the user are given | . Main Success Scenario: | Flow updated | . Failure Scenario: | Updating the flow was not successful | . Basic Workflow: | 1. Define user 2. Define flow 3. Retrieve flow | . Alternative Workflow: | 1a. User is unknown 2a. Incorrect flow defined 3a. Throw error | . Label USE CASE - Delete Integration Flow . Actor: | User | . Summary: | Describes deleting a given integration flow | . Trigger: | A user wants to delete an integration flow | . Preconditions: | Credentials for the user are given | . Main Success Scenario: | Flow deleted | . Failure Scenario: | Updating the flow was not successful | . Basic Workflow: | 1. Define user 2. Define flow 3. Retrieve flow | . Alternative Workflow: | 1a. User is unknown 2a. Incorrect flow defined 3a. Throw error | . As described in the document identity management (s. SecureAccessControl/Identity Management.md) the OIH consists of multiple services and agents with different roles and authorization. These roles and their authorizations have to be considered. . Technology Used . Storing, updating and retrieving the JSON-flows could be done in a simple GIT-Repository. This is can be simple implemented. . Concept of the Flow Repository . As described in the document integration services (s. /IntegrationServices.md) the Flow Repository is positioned between the Scheduler and the Resource Coordinator. . The Scheduler helps to perform the polling of the integration flows periodically. The Resource Coordinator enforces every tenant to comply with the defined policies on resource sharing. . The communication with the other microservices within the OIH is done via an API (to be specified). . The flows are specified in JSON, therefore we store and retrieve them in JSON. The JSON-Format of the flows has to be specified. . The following requests can be done: . Retrieve all flows: Returns all flows belonging to the given user. If the user is a member of an organization, all the flows of the organization are returned. If the user is a member in multiple organizations, the given authentication is used to match the proper organization. | Retrieve a flow by id: Returns the flow with the given ID. | Store new flow: Returns the stored given flow. | Update flow by id: Returns the updated given flow. | Delete flow by id: Return the id of the deleted given flow. | .",
    "url": "http://localhost:4000/docs/Services/FlowRepository.html",
    "relUrl": "/docs/Services/FlowRepository.html"
  },
  "4": {
    "title": "Indentity Access Management",
    "content": "Identity Management . This document describes the evaluation of identity and access management within the Open Integration Hub. . ## Why is Identity and Access Management necessary? . ## Types of identities OIH consists of multiple services and agents with different roles and authorization. Given the fact, that we are dealing primarily with machine-to-machine interaction, we can use machine identites (aka. Service Accounts) for authentication and authorization of these machines. . ## Which entities should be managed? . We can cluster the digital identites of OIH into three categories: . Master (e.g. administrative application which managed the OIH via REST-API) | Connector | Tenant | . ### Master This actor has a privleged admin access to OIH and can define which Connectors should be (de)-provisioned. This actor can also define intergration flows on behalf of a tenant between two or more ISV connectors. Additionally, this system is authorized to manage identites/accounts (e.g. service accounts) for connectors, tenants, etc. . ### Connector A connector is a service which can trigger an action on behalf of the user or master, e.g. create a tenant, modify tenants customer data. This requires the connector to provide a valid access token or a valid service account containing these priveleges. The required privilges are granted by tenant account (or tenant admin) through OIH. Whenever such change occurs, the connector could send an event to OIH providing it’s access token. OIH verifies the access token and the claims. . ### Tenant and Tenant Users Each tenant and tenant users have an identity in OIH (main identity). Whenever a tenant account is created in one of the ISV systems via OIH, a new remote identity is created in OIH and linked to the main identity. This creates a relation (a graph) between the main identity and all corresponding remote identites. Tenant (or tenant admin) have access to tenant resources and can grant access to a connector via OIH to read/write to these resources. Example: tenant can grant access to an ISV connector C1 read and write access to it’s customer data and another ISV Connector C2 only read access. These access grants are required to define an integration flow of customer data from C1 to C2. . . In a very basic scenario one could use a Master account to provision connectors, to manage tenants, etc. . The Master account is preveleged to create a Tenant and thus a tenant identity. For any further API calls to OIH on behalf of the tenant organization (e.g. to create the tenant in one of the vendor application through a corresponding Connector) it could be favorable to use the tenant identity instead of the Master identity. This allows for authorization mechanisms by design and better means of audit logging. In case of a marketplace like Basaas, the Tenant and all Tenant users SSO mechanisms are managed by the marketplace. This also means, that the marketplace could store and transmit for each Tenant their specific Token/Service Account. To accomplish that, the Master system like the marketplace would also need either to store these Tokens/Service Accounts or to be able to fetch them from OIH. . The following example workflow tries to illustrate such scenario: . Master System uses service account to create a tenant | OIH creates tenant | Master System fetches the tenant service account and stores it for future requests | Tenant admin creates an account in the solution ACME Inc. | Master System uses the tenant service account to create a tenant account in ACME Inc. through OIH | OIH triggers the Connectorto create the tenant in ACME Inc. | Connector creates tenant and returns it’s internal TenantId | OIH saves the new TenantId and connects it to the existing OIH tenant-id | . Following figure illustrates the services and the identities/service accounts. . . Another case of identities in use is when a Connector requires authorization for a vendor backend. Assuming an ISV named ACME Inc. has an RESTful API with OAuth 2.0 support. ACME creates a Connector. For every REST call the connector has to provide a valid access token for the associated tenant account. Given that a connector has no persistence, such tokens and other authentication/authorization mechanisms can be stored and provided from OIH. A possible workflow might be as follows: . OIH and connector negotiate the supported authentication methods between OIH ↔ Connector ↔ ACME Backend or the OIH supports only OAuth 2.0 and requires access token for ACME | OIH triggers a connector to create a tenant account in ACME and provides an access token for this operation | Connector calls ACME backend with the given token and creates a tenant on behalf of OIH | ACME returns new access token for this particular tenant | Connector transmits this tenant specific access token to OIH | OIH saves the token and either uses it for all future calls for this particular tenant or provides means for a connector to fetch such token when needed | Tenant admin creates an action through OIH | OIH requests tenant consent (UI) and triggers the requested action afterwards | . . There are most likely different strategies/possibilities to use identity management to perform actions on behalf of the user. Some of these actions may be: . Modify use data, e.g. user changed her lastname | Extract tenant data from an ISV and import that data into another ISV | . Given the fact that some ISVs may have an existing API based on OAuth, Rest with Access Control, etc. we must consider if there is a “one size fits all” solution or whether the OIH must be capable of applying different strategies, e.g. requiring user’s authorization by using her identity in context of OAuth 2. . ## Identity Resources and Identity provider . The conceptual design of OIH allows the use of custom data models and integration flows of such data between multiple ISVs via connectors. An example of such data is customer data. In a simplified scenario without a data hub, a tenant can define which ISV should be primary or leading system for a specific data model (in this case – customer data). This could mean, that this ISV could be in theory the resource provider for customer data. This leads to an assumption, that we may not have a centralized resource provider without a data hub. Each ISV could be granted the privilege of a resource provider. Each caller trying to access such data must provide a valid access token established by the identity provider. An ISV connector may require a Resource API as part of it’s SDK to be able to access and validate tokens. TBD: conceptual design and analysis of federated identites. . ## Machine-to-Machine Authentication/Authorization . A machine-to-machine authorization is when the client makes calls to the Resource Server (i.e. the API) on its own behalf. For situations like this where there is no user interaction involved, the Client Credentials Grant is ideal. With Client Credentials Grant (defined in RFC 6749, section 4.4) a Client can directly request an access_token from the Authorization Server by using its Client Credentials (a Client Id and a Client Secret). Instead of identifying a Resource Owner, this token will represent the Client itself. See: https://auth0.com/docs/architecture-scenarios/application/server-api/part-1 . ## Challenges . Multiple Services are using the same OAuth2 Access Token. One Service uses the Refresh Token which creates a new Access Token and invalidates the previous token. How should the services handle this? |",
    "url": "http://localhost:4000/docs/Services/IdentityManagement.html",
    "relUrl": "/docs/Services/IdentityManagement.html"
  },
  "5": {
    "title": "Message Oriented Middleware",
    "content": "Introduction . The message oriented middleware is a central part of the Open Integration Hub and is needed to store and route messages while transferring them from senders to receivers. . Description . The documents describes an integration flow and how two steps are connected via a message oriented middleware. . Technologies used . RabbitMQ | . Reasoning . RabbitMQ can handle more than 1M messages per second. Additionally to that, Organizations in XPC are not communicating with each other, which gives us a perfect case for horizontal scalability - we deploy multiple RabbitMQ instances to handle load linearly. . Conceptional Elaborations . An integration flow is represented by a directed acyclic graph in which nodes are represented by integration components communicating with a particular API or executing some custom logic. The edges of the integration graph define which of two components are connected. . An integration flow is executed by number of Pods, each representing a flow’s node, also called a flow step. The steps communicate which each other through a messaging queue, such as RabbitMQ. The following diagram displays an example of an integration flow using a message broker. . . In the diagram above Step 1 is a trigger component producing data by polling an API periodically. The produced messages are sent to a queue connecting Step 1 and Step 2. Because the component in Step 2 is very slow, its consumption rate is lower than the publish rate. The result is that the queue is growing. That’s why 2 instances of Step 2 are started, each consuming messages from the same queue. The message broker makes sure that the messages are sent to a single consumer only. .",
    "url": "http://localhost:4000/docs/Services/MessageOrientedMiddleware.html",
    "relUrl": "/docs/Services/MessageOrientedMiddleware.html"
  },
  "6": {
    "title": "Meta Data Repository",
    "content": "Introduction | Description Purpose of the Microservice Meta Data Repository | . | Technologies used | Service Implementation | Requirements | Conceptional Elaborations Basic Version Model Structure Domain Object | Model Object | . | . | . | Open questions / Discussion How does a transformer pass/reference the model from metadata repository | Where is the transfomer output validated | oihdatarecord | . | User Stories | . Introduction . The meta data repository is responsible for storing domains and their master data models. The models stored within this service are consulted for different tasks such as data validation. The meta models are also used by the transformer to map the incoming data onto the Open Integration Hub standard. . In addition, this service also manages the oihdatarecord and concatenates it with the master data models. . Description . Purpose of the Microservice Meta Data Repository . If we talk about metadata in this context, we mean the description of the domains and their corresponding Master Data Models. An OIH Master Data Model (OMDM) describes the data of a certain domain in a depth which is sufficient enough to map and synchronize the specific data of multiple applications in that domain. The meta data delivers all the information a user or customer needs to work with data within a specific domain. . The domain models are specified by special workgroups. Please see the specific domain model repository for further informations on a domain and its master data model. . Technologies used . For storing the meta data this service could use MongoDB. We will use Mongoose for object modeling. Mongoose is built on top of the official MongoDB Node.js driver. For documenting the API we will use the SwaggerUI. . This is a common technology stack and widely used inside the OIH. . Service Implementation . Framework Part: Tbd . Reference Implementation: meta data repository . Requirements . Some required functionalities of the meta data service can be derived from the already designed Smart Data Framework API: . Create a new domain | Create a new master data model for a domain | Retrieve a list of all domains for an authenticated user | Retrieve a specific domain | Retrieve a list of all model for an authenticated user | Retrieve a specific model | Retrieve all models for a specific domain for an authenticated user | Update a domain | Update a master data model | Delete an existing domain (and all relating models) | Delete an existing master data model | Add the oihdatarecord schema to a master data model when the model is requested | . For some user stories see section user stories. . Conceptional Elaborations . Basic Version . Model Structure . As aforementioned the service is mainly responsible for storing meta models and domains. In order to unify the meta data to describe domains and models we need a model structure for both objects. . Domain Object . The domain object is responsible describing the domain itself. Thus, the following object structure is proposed: . { &quot;$schema&quot;:&quot;http://json-schema.org/draft-06/schema#&quot;, &quot;$id&quot;:&quot;http://json-schema.org/draft-06/schema#&quot;, &quot;title&quot;:&quot;Domain object description&quot;, &quot;properties&quot;:{ &quot;id&quot;:{ &quot;type&quot;:&quot;string&quot;, &quot;description&quot;:&quot;Unique identifier of the domain&quot;, &quot;examples&quot;:[ 1 ] }, &quot;name&quot;:{ &quot;type&quot;:&quot;string&quot;, &quot;description&quot;:&quot;Name of the domain&quot;, &quot;examples&quot;:[ &quot;products&quot; ] }, &quot;description&quot;:{ &quot;type&quot;:&quot;string&quot;, &quot;description&quot;:&quot;Short description of the domain&quot;, &quot;examples&quot;:[ &quot;This domain includes all product related models&quot; ] }, &quot;owners&quot;:{ &quot;type&quot;:&quot;array&quot;, &quot;description&quot;:&quot;List of owners, who have access to this domain&quot;, &quot;items&quot;: { &quot;properties&quot;: { &quot;id&quot;: { &quot;type&quot;: &quot;string&quot; }, &quot;type&quot;: { &quot;type&quot;: &quot;string&quot; } } }, &quot;examples&quot;:[ { &quot;id&quot;: &quot;5bffec99a43c7f3ca95b09e6&quot;, &quot;type&quot;: &quot;tenant&quot; } ] } } } . Model Object . The model object is responsible for describing the meta model and should have a reference to the superordinated domain. Therefore, the following structure is supposed: . { &quot;$schema&quot;:&quot;http://json-schema.org/draft-06/schema#&quot;, &quot;$id&quot;:&quot;http://json-schema.org/draft-06/schema#&quot;, &quot;title&quot;:&quot;Domain object description&quot;, &quot;properties&quot;:{ &quot;id&quot;:{ &quot;type&quot;:&quot;string&quot;, &quot;description&quot;:&quot;Unique identifier of the model&quot;, &quot;examples&quot;:[ &quot;13&quot; ] }, &quot;domaindId&quot;:{ &quot;type&quot;:&quot;string&quot;, &quot;description&quot;:&quot;Unique identifier of the domain the model belongs to&quot;, &quot;examples&quot;:[ &quot;1&quot; ] }, &quot;description&quot;:{ &quot;type&quot;:&quot;string&quot;, &quot;description&quot;:&quot;Short description of the model&quot;, &quot;examples&quot;:[ &quot;Master Data Model Products v1&quot; ] }, &quot;owners&quot;:{ &quot;type&quot;:&quot;array&quot;, &quot;description&quot;:&quot;List of owners, who have access to this domain&quot;, &quot;items&quot;: { &quot;properties&quot;: { &quot;id&quot;: { &quot;type&quot;: &quot;string&quot; }, &quot;type&quot;: { &quot;type&quot;: &quot;string&quot; } } }, &quot;examples&quot;:[ { &quot;id&quot;: &quot;5bffec99a43c7f3ca95b09e6&quot;, &quot;type&quot;: &quot;tenant&quot; } ] }, &quot;model&quot;:{ &quot;type&quot;:&quot;object&quot;, &quot;description&quot;:&quot;A JSON schema of the actual model&quot;, &quot;examples&quot;:[ { &quot;$schema&quot;:&quot;http://json-schema.org/schema#&quot;, &quot;$id&quot;:&quot;https://github.com/openintegrationhub/Data-and-Domain-Models/blob/master/src/main/schema/addresses/personV2.json&quot;, &quot;title&quot;:&quot;Person&quot;, &quot;description&quot;:&quot;Describes a natural person&quot;, &quot;type&quot;:&quot;object&quot;, &quot;allOf&quot;:[ { &quot;$ref&quot;:&quot;../oih-data-record.json&quot; } ], &quot;properties&quot;:{ &quot;title&quot;:{ &quot;type&quot;:&quot;string&quot;, &quot;description&quot;:&quot;Title of the person&quot;, &quot;examples&quot;:[ &quot;Dr.&quot; ] }, &quot;salutation&quot;:{ &quot;type&quot;:&quot;string&quot;, &quot;description&quot;:&quot;Salutation of the person&quot;, &quot;examples&quot;:[ &quot;Mr.&quot; ] }, &quot;firstName&quot;:{ &quot;type&quot;:&quot;string&quot;, &quot;description&quot;:&quot;Given name of the person&quot;, &quot;examples&quot;:[ &quot;Max&quot; ] } } } ] } } } . Open questions / Discussion . How does a transformer pass/reference the model from metadata repository . For each transformer in a flow, the user could define which domain + models should be used. When a transformer creates an output how does it reference the exact model representing the data? The transformer could support multiple models, but in order for OIH to validate and process the output, it needs at least to know which model matches which output. Are models named, e.g. person and the domain is preselected by the user, when configuring the transfomer? . The Master-Data-Model document defines following requirement: . for every sub-model of an OMDM there must be a seperate JSON schema describing the entity or aggregate. Can a person be a sub-model of addresses with a unique URI? . Where is the transfomer output validated . Done by a separate validator component or metadata repository? | . oihdatarecord . In order for the transformer to embed the oihdatarecord into the model via allOf, it needs the reference/uri of the oihdatarecord, e.g. env vars. . User Stories . User Story Id User Story . uMs-meDa1 | As an OIH operator I want to upload new versions of a master data model, so that I always the newest model version is stored in my OIH instance | . uMs-meDa2 | As an OIH operator I want to delete existing models, so that only the newest model version is stored | . uMs-meDa3 | As a customer I want to upload new master data models, so that I can choose from a variety of models for a domain | . uMs-meDa4 | As a customer or OIH operator I want to upload new domains, so that I can operate in further domains | . uMs-meDa5 | As a customer I want to retrieve a list of all my domains, to get an overview of all domains I can operate with | . uMs-meDa6 | As a customer or OIH operator I want to retrieve information about a specific domain, so that I can see information about the domain and all its models | . uMs-meDa7 | As an OIH operator I want to retrieve a list of all domain models available for a specific user, so that the user is able to choose which model he/she wants to use | . uMs-meDa8 | As an OIH operator I want to retrieve a specific model, so that I can generate a dynamic mapping interface that I can provide my customer | . uMs-meDa9 | As a customer I want to retrieve a specific model, so that I know the structure of the model and write a mapping between my data model and the master data model | . uMs-meDa10 | As an OIH operator I want to retrieve a specific model, so that I can validate the output of a transformer | . uMs-meDa11 | As an OIH operator I want to be able to store multiple versions of one model, so that backward compatibility is ensured | . uMs-meDa12 | As an OIH operator I want that a user can only see the domains he is authorized for | . uMs-meDa13 | As an OIH operator I want that a user can only see the models he is authorized for | . uMs-meDa14 | As an OIH operator I want that a user can only delete domains he is authorized for | . uMs-meDa15 | As an OIH operator I want that a user can only delete models he is authorized for | .",
    "url": "http://localhost:4000/docs/Services/MetaDataRepository.html",
    "relUrl": "/docs/Services/MetaDataRepository.html"
  },
  "7": {
    "title": "Scheduler",
    "content": "Introduction . The service scheduler is responsible for a periodical execution of integration flows. . Description . The document shortly describes the service and its functionality. . Technologies used . Cron-Deamon | . Service Implementation . Framework Part: scheduler lib . Reference Implementation: scheduler service . Conceptional Elaborations . Scheduler . In the Integration Hub there is a great number of active integration flows to be executed periodically. Each integration can be configured with a Cron expression defining flow’s execution interval. Let’s consider the following Cron expression: . */3 * * * * . The cron expression above executes an integration flow at every 3rd minute starting from the flow’s start time. . With the following Cron expression a flow is executed every Sunday at 6:00 am: . 0 6 * * 7 . The Scheduler iterates over all active integration flows and evaluates their Cron expressions. Is a flow due to be executed, Scheduler tells the Resource Coordinator to deploy the integration flow for execution. .",
    "url": "http://localhost:4000/docs/Services/Scheduler.html",
    "relUrl": "/docs/Services/Scheduler.html"
  },
  "8": {
    "title": "Secret Service",
    "content": "Introduction . In an environment similar to OIH different services communicate with each other but also with external cloud services. Such external services normally require some sort of authentication and authorization in order to identify the communicating party and the it’s privileges. Typically RESTful APIs tend to secure the API with API-Keys and tokens (e.g. OAuth 2.0 tokens). The usage of certificate in combination with a private certificate authority is also possible, but this document does not focus on the concept of a Public Key Infrastructure. From a security point of view, it is reasonable to store API-Keys and tokens encrypted and have strong authorization mechanisms to access them. In a multi-tenant environment – ideally using different encryption keys for each tenant. In OIH we need an appropriate storage for tenant or user specific key value pairs, whereupon the value can be an encrypted string, certificate, etc. All stored keys and tokens should be accessible via an API if a valid authorization exists. . Service Implementation . Framework Part: secret-service lib . Reference Implementation: secret-service service . Use Cases and requirements in OIH . When dealing with integration flows there are different scenarios when secrets are required. Here are some examples: . Store an API-Key and use it for a specific solution in context of a specific integration flow. | Store the access &amp; refresh tokens (OAuth 2.0) acquired through user consent. | Allow sharing of secrets with other users/groups but limit read &amp; write access to the keys only to authorized users. | A connector which runs in context of an integration flow created by the user/tenant must be able to receive the required keys/tokens. | Additionally, it is essential to have a sophisticated audit logging for all operations involving these secrets. . Secret Service . A dedicated service should carry out the management of keys and secrets. Keys need to have at least one owner and the ownership should be validated through OIH IAM. Additionally, the underlying vault framework should be interchangeable through an abstraction layer, thus ensuring a stable public API. . The Secret-Service will provide a CRUD-API for keys, which can be accessed by other privileged services, e.g. flow operator or even connector, as well as the users. The API may look similar to current elastic.io credentials API https://api.elastic.io/v2/docs/#credentials . Proposal for secret structure . { &quot;_id&quot;: &quot;59f9f2ba112f28001921f274&quot;, &quot;type&quot;:&quot;credential&quot;, &quot;name&quot;: &quot;MySecret&quot;, &quot;attributes&quot;: { &quot;keys&quot;:{ &quot;host&quot;:&quot;sftp.company.org&quot;, &quot;username&quot;:&quot;testuser&quot;, &quot;password&quot;:&quot;testpassword&quot; } }, &quot;owners&quot;: [ { &quot;entityType&quot;: &quot;USER&quot;, &quot;entityId&quot;: &quot;59f747c33f1d3c001901a44e&quot; }, { &quot;entityType&quot;: &quot;USER&quot;, &quot;entityId&quot;: &quot;59f747c33f1d3c001901a44f&quot; }, { &quot;entityType&quot;: &quot;TENANT&quot;, &quot;entityId&quot;: &quot;59f747c33f1d3c001901a43e&quot; } ], &quot;meta&quot;:{} } . Access control . To enforce authentication and authorization, the Secret-Service service must also store the owner or owner group, e.g. secret is owned by user with id XYZ. Similar to current elastic.io model, flow and credentials can have a group (workspace in elastic.io documentation) as an owner. If each user has at least her own private group and each tenant likewise, then the credentials owner can be described as an array of groups. . . Credential ownership ensures, that only users belonging to the correct group/workspace are allowed to read/modify the secrets. . Apart from users, connectors also require access to credentials, e.g. when the user creates a flow and configures her credentials to be used in a specific flow step. . There are two alternatives to solve this . The service responsible for connector instantiation provides the connector with all required secrets | Each connector receives a token with which it can fetch the secrets from Secret-Service | With the second alternative we can make sure, that each connector has access only to specific secrets by providing them with a corresponding JWT token from IAM service. This JWT token would contain as a claim the user’s group-id. This in return allows the Secret-Service to verify that the connector accesses only the credentials it actually is authorizes to read. Still, this seems a bit over-engineered compared to the first one. The second alternative does however make sense if it combined with the feature of AccessToken Auto-Refreshing. . As IAM currently does not have or support the concept of groups, we will implement the access control in the first phase as a tuple of entityType and entityId, e.g. . { &quot;entityType&quot;: &quot;USER&quot;, &quot;entityId&quot;: &quot;59f747c33f1d3c001901a44e&quot; }, { &quot;entityType&quot;: &quot;TENANT&quot;, &quot;entityId&quot;: &quot;59f747c33f1d3c001901a44f&quot; } . and later as only a groupId, which must also exist in IAM. . The following diagram illustrates both alternatives. . . Flows, Connectors and Credentials . In an integration flow, each connector represented as a node, could receive it’s own JWT token containing the claims to access those credentials, which are required in this specific step. This could be accomplished for example through scheduler or flow manager, which ever is responsible for creation of connector instances and passing of environment variables to them. The connector then can fetch all required secrets from Secret-Service and provide the JWT token containing the claims. The Secret-Service validates the request and returns the secrets, if the connector is authorized to access them. . The JWT payload could contain as less as the secret ids required for this specific integration step. The same ids could be present in the flow data payload, which the connector receives from the queue upon initialization. . Summary . Service account(s) or JWT for a connector to fetch secrets | Adapter communicates with an external application and requires user’s secret Adapter either fetches the secrets itself from secrets service using it’s own service account and context (context may be the flow or flow step, and thus limit the access only to secrets of flow owner) | or receive the secret as env vars through a superordinate priveleged service | . | In case of OAuth access tokens, a separate service could be used to refresh access tokens (singleton) and all services using an access token must request it from this singleton service Advantage: only one token refresh, all depending connectors fetch the new access token from this service | . | Secrets are stored encrypted | Access control to secrets is based on IAM authentication and authorization mechanisms | Secret-Service has it’s own mongodb, where it stores: secret_id (secret is stored in vault, but referenced through secret_id), owner (user or tenant) | Secret-Service can fetch and return a new access token using the refresh token it stored in vault | . Secrets management framework . Our research for a suitable and mature solution lead us to HashiCorp Vault, which we will be using for our prototypical implementation. Other solutions should be possible to integrate, as the Secret-Service acts also as an abstraction layer of the underlying vault framework. This allows to interchange the vault framework through other solutions, as long as the Secret-Service API persists. . For a list of secrets managements solutions (albeit focused more on infrastructure and possible not up-to-date) please see this comparison list: . https://gist.github.com/maxvt/bb49a6c7243163b8120625fc8ae3f3cd . https://www.vaultproject.io/intro/vs/index.html . Requirements . Strong Encryption of stored secrets | HA capability | An open source project with a large community and activity | Maturity of the framework | Good documentation | Flexible storage choice | Enterprise ready | . Compared to other solutions, we find that HashiCorp Vault fits best with our requirements. . Access Token Auto-Refreshing . In the section Access Control we mentioned an alternative where connectors fetch the secrets directly from the Secret-Service. This approach has an advantage if at some point either Secret-Service or a correlating service also manages OAuth access tokens. In practice, this means that a connector would call Secret-Service an request an access token of a specific OAuth secret. The Secret-Service can then either return the access token, if it has a valid one or fetch the access token using for example client id and client secret. If more than one connector rely on a single access token (an identical access token), then fetching and refreshing of an access token is done ideally by a singleton – in our case Secret-Service or a correlating service responsible for this types of requests. .",
    "url": "http://localhost:4000/docs/Services/SecretService.html",
    "relUrl": "/docs/Services/SecretService.html"
  },
  "9": {
    "title": "Service Collaboration",
    "content": "Introduction . This document is designed to describe different service collaboration examples. It should act as a starting point to easily understanding the architecture of the Open Integration Hub. Most of the examples are triggered by user interactions (e.g. starting a flow) and only the “happy path” i.e. success scenario is described. . Each example is described through a graphical overview, a textual description and pre-conditions. For further information for a specific version please have a look at the services itself. . Introduction Starting a flow Detailed Service Consideration Flow repository | Webhooks | Scheduler | . | . | Execute Polling Flow | Execute Webhook Flow POST Request | GET Request | . | Request Resources | Creating audit log records | . | . Starting a flow . Pre-Conditions: None. . This example describes the scenario of starting a flow. Once the user starts a flow the following steps are processed: . Client starts a flow using flow repository’s REST API. | Flow Repository sets the flow’s status to starting and raises the event flow.starting. | There are 3 services listening to the event flow.starting: Webhooks, Scheduler and Component Orchestrator. Webhooks and Scheduler examine the event’s payload and decide if they need to react appropriately. We will discuss the exact reaction of both services later in this document. | Upon receiving flow.starting event the Component Orchestrator starts deploying the containers. Once all containers were deployed, Component Orchestrator raises the flow.started event. | Flow Repository receives the flow.started event and switches flow’s status property from starting to started. | Webhooks receives the flow.started event and starts receiving incoming HTTP calls for the given flow. | Scheduler receives the flow.started event and starts scheduling the flow, according to it’s cron property. | When a client stops a running flow using flow repository’s REST API, the event flow.stopping is raised which is causing an inverse reaction chain of events. | . Figure: startFlow . Detailed Service Consideration . Now let’s discuss the individual services in details. . Flow repository . POST /flows/{id}/start: Used to start a flow | POST /flows/{id}/stop: Used to stop a flow | . Upon receiving the HTTP call for starting a flow, Flow Repository sets the flows status to starting. Upon receiving stopping request it sets the status to stopping. If the flow has been started and flow repsitory receives flow.started event it sets the status to active while it sets it to inactive upon receiving flow.stopped. The schema of the event payload is shown below. . Event: type: object required: - headers - payload properties: headers: type: object required: - name - createdAt - serviceName properties: name: type: string createdAt: type: string format: date-time serviceName: type: string payload: type: object . The payload property is an arbitrary object to be sent with the event. Flow repository will send the entire flow as payload. . Webhooks . Upon receiving flow.starting event the service checks if the cron property is not set. If so, the service persist a data record in his local DB but doesn’t start receiving HTTP requests for the given flow yet. The following table demonstrates an example of such records. . flowId queue . 58b41f5da9ee9d0018194bf3 | queue_58b41f5da9ee9d0018194bf3 | . 5b62c91afd98ea00112d5404 | queue_5b62c91afd98ea00112d5404 | . After receiving the flow.started event, the service starts accepting incoming messages from the flow’s webhook URL and sends them to the corresponding queues to be handled by flow nodes. This is actually how it is accomplished today. The only difference is that webhooks service is retrieving all the required data about a webhook flow from its local DB. . Please note that the webhooks service ignores the event if the following condition is met: . cron property is set in the event | . Upon receiving the flow.stopping event, the service deletes the record for the given flow and stops accepting requests. . Scheduler . Upon receiving flow.starting event the service checks if the cron property is set. If so, the service persist a data record in his local DB, but doesn’t start scheduling the given flow yet. The following table demonstrates an example of such records. . flowId cron dueExecution . 58b41f5da9ee9d0018194bf3 | */3 * * * * | 2019-01-25T13:39:28.172 | . 5b62c91afd98ea00112d5404 | 15 14 * * 1-5 | 2019-01-27T14:15:00.00 | . Upon receiving the flow.started event the service starts scheduling the flow executions by retrieving the flow data from its local DB. . Please note that the scheduler service ignores the event if the following condition is met: . cron property is not set in the event | . Upon receiving the flow.stopping event, the service deletes the record for the given flow and stops scheduling flow executions. . Execute Polling Flow . Pre-Conditions: Starting a flow. . As described in scheduler section when a flow is started the service starts scheduling the flow executions. Once the scheduler finds a flow that is ready for execution it pushed a message including the relating flow ID to the queue. The recipient is the first node of the flow which is the application specific adapter. This adapter then makes a GET request to the aplications API to get the payload. Afterwards it pushes the message including the payload onto the queue. . The message format of the messages emitted by scheduler have the following structure: . { &quot;id&quot; : //some record uuid, &quot;attachments&quot;:{ //empty }, &quot;body&quot;: { //empty }, &quot;headers&quot;: { //empty }, &quot;metadata&quot;: { //empty } } . . Figure: executePollingFlow . Execute Webhook Flow . POST Request . Pre-Conditions: Starting a flow. . Once Webhooks receives a POST request it pushes the message to the queue. The recipient is the first node of the flow which is the application specific adapter. In contrast to the GET request, this request already includes the payload. . The following example shows the message format of Webhooks messages: . { &quot;headers&quot;: { //GET request headers }, &quot;query&quot;: { //POST request query parameters }, &quot;body&quot;: { //POST request body }, //other properties } . . Figure: executeWebhookFlowPost . GET Request . Pre-Conditions: Starting a flow. . Once Webhooks receives a GET request it takes the url parameters and request headers and put it into the message. This means in particular the headers go to headers while query string parameters go to body. It then pushes the message to the queue. The recipient is the first node of the flow which is the application specific adapter. This adapter then makes a GET request to the aplications API to get the payload. Afterwards it pushes the message including the payload onto the queue. . The following example shows the message format of Webhooks messages: . { &quot;headers&quot;: { //GET request headers }, &quot;body&quot;: { //GET request query string parameters }, //other properties } . An examplary webhook GET request could look like the following: GET /hook/&lt;flow-id&gt;?param1=value&amp;param2=value . . Figure: executeWebhookFlowGet . Request Resources . The following example shows how a user can request a resource using IAM. The graphic below shows how this example would look like if a user request a resource from the flow repository. . User logs in into IAM. | IAM responds with an ephemeral token. | User uses the ephemeral token to request a cetrain resource (e.g. a specific flow by id). | Flow repository introspects the ephemeral token at IAM (services accounts receive a permanent token when they first register) using IAM utils (middleware). | IAM responds with user information such as username, tenant, tenant specific role and user permissions related to this token. | Flow Repsitory checks if the user has the permission to request the resource. | Flow repository responds with the requested information. | Illustration of this process: (Figur requestResourceSuccess). . . Figure: requestResourceSuccess . 1: Ephemeral token 2: Service makes request with service account token 3: User information e.g.: username, tenant, tenant specific role, permissions . Creating audit log records . To create a record that should be stored in the audit log a service simply has to put a message onto the queue with a predefined topic. Each service decides on its own, which events should be stored in the audit log service. Audit log listens to all events having audit.* as topic. . .",
    "url": "http://localhost:4000/docs/Service%20Collaboration/ServiceCollaborationOverview.html",
    "relUrl": "/docs/Service%20Collaboration/ServiceCollaborationOverview.html"
  },
  "10": {
    "title": "Services",
    "content": "Introduction . This folder contains the documentation about the Open Integration Hub Services. A short version of the functionalities can be found below: . Integration Component (Adapter) Repository . The integration components are lightweight and stand-alone Docker images that include everything needed to run the component, including the component’s code, a runtime, libraries and dependencies. The component images are stored in an integration component repository: Integration Component Repository. . Scheduler and Resource Coordinator . There are two ways to trigger a flow execution: to poll changes periodically or to receive notifications through webhooks. The majority of integration flows poll perform polling as the most of APIs out there don’t support webhooks. The polling is performed periodically with the help of the Scheduler. . Because Integration Hub is a multi-tenant environment, it is theoretically possible that some tenants cause starvation of others through an unfair usage of shared resources. The Resource Coordinator enforces every tenant to comply with the defined policies on resource sharing. . Please read more details on scheduler and resource coordinator: SchedulerResourceCoordinator. . Communication Router . In contrast to polling a flow can be started by an external event. Modern APIs provide support for webhooks in order to avoid wasting of resources when polling. The external system can be configured with a webhook url to be called upon changes in the external system. The Communication Router is used to expose externally-reachable URLs for integration flows that can be used to implement webhook-triggered flows. These URLS may be registered in external systems to sent notifications to. See more details on communication router: MessageProcessing/CommunicationRouter. . Logging &amp; Monitoring . Integration Hub micro-services and integration flows are running in a Kubernetes cluster. Read details on cluster-level logging architectures: ManagementServices/LoggingMonitoring. . Message Oriented Middleware . All the communication between steps of an integration flow in runtime is happening through a message broker. Two steps of an integration flow are separate Docker container isolated from each other. They are connected through a messaging queue than provides them a reliable and asynchronous communication protocol. See more details on message oriented middleware: MessageProcessing/MessageOrientedMiddleware. . Secure-Key-Management . An integration flow defines how data flow between various external systems and how these data are transformed between steps of that flow. However an integration flow does not define how to connect to these external systems. An integration can be considered as a clonable template that must not contain any sensible user data, such as API credentials. The API credentials are stored in the secure-key-management: SecureAccessControl/SecureKeyManagement). . Identity and Access Management . Identity and Access Management (short: IAM) is one of the core components in OIH which is needed to provide a secure authentication and authorization of users/clients. The IAM Service can be configured to use JWT tokens with HMAC or RSA. It has also support for OpenId Connect: IAM Concept) . Integration Content Repository . All connected solutions to the Open Integration Hub and the work they are doing there are represented by an “integration flow”. These flows have to be stored, retrieved, updated and deleted. The Integration Content Repository will provide these functionabilities: /RepositoryManagement/IntegrationContentRepository .",
    "url": "http://localhost:4000/docs/Services/Services.html",
    "relUrl": "/docs/Services/Services.html"
  },
  "11": {
    "title": "Home",
    "content": "",
    "url": "http://localhost:4000/",
    "relUrl": "/"
  },
  "12": {
    "title": "Component Orchestrator",
    "content": "The OIH microservices mostly communicate asynchronously and via message queues. Most services emitts and consumes several events. . This document is designed to list all (for now: audit log relevant) events per service. . The currently used Event format provided by the Event Bus library was adopted for overall use. The schema is: . { &quot;headers&quot;: { &quot;serviceName&quot;: &quot;string&quot;, &quot;createdAt&quot;: &quot;date&quot;, &quot;name&quot;: &quot;string&quot;, }, &quot;payload&quot;: { &quot;user&quot;: &quot;string&quot;, &quot;tenant&quot;: &quot;string&quot; } } . The field contents are: . headers: An object containing metadata about the event itself serviceName: The name of the spawning service. If using the event-bus module, this will be filled in automatically | createdAt: A timestamp of the event’s creation. If using the event-bus module, this will be filled in automatically. | name: The name of the event. Also doubles as its routing key. | . | payload: An arbitrary JSON object, containing the content of the event. Two optional fields are reserved for logging purposes: user: The IAM-ID of a user who spawned the event | tenant: The IAM-ID of a tenant in which this event occurred | . | . IAM . General Events . User created - iam.user.created . | User removed - iam.user.deleted . | Tenant created - iam.tenant.created . | Tenant removed - iam.tenant.deleted . | . AuditLog Events . User: | . Created, modified, deleted, assigned/removed to/from tenant, failed login attempt | e.g. iam.user.[operation] | Tenant: | . Created, modified, deleted | e.g. iam.tenant.[operation] | Token / Roles / Permissions: | . Created, modified, deleted | e.g. iam.role.[operation] | Secret-Service . AuditLog Events . Secret: | . Created, deleted | e.g. secret-service.secret.[operation], secret-service.auth-client.[operation] | Access Token requested by Account: | . e.g. secret-service.token.get | Metadata . AuditLog Events . Domain / Schema | . Created, modified, deleted | E.g. metadata.schema.[operation] | Flow Repository . AuditLog Events . flowrepo.flow.created | flowrepo.flow.modified | flowrepo.flow.deleted | flowrepo.flow.starting | flowrepo.flow.stopping | . Component Orchestrator . AuditLog Events . flow.started | flow.stopped | .",
    "url": "http://localhost:4000/docs/Service%20Collaboration/serviceEvents.html",
    "relUrl": "/docs/Service%20Collaboration/serviceEvents.html"
  }
  
}
